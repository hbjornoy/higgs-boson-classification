{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# own functions\n",
    "\n",
    "import proj1_helpers as P1H\n",
    "import dataprocessing as DP\n",
    "import methods as ME\n",
    "import cross_validation as CV\n",
    "from grad_loss import*\n",
    "\n",
    "#constants\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_y, orig_x, orig_ids = load_csv_data(train_path, sub_sample=False) #remember to switch of subsample when running it \"for real\"\n",
    "pred_y, pred_x, pred_ids = load_csv_data(test_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To provide clarity to which data I am processing\n",
    "x = np.copy(orig_x)\n",
    "\n",
    "# Cleans values that are -999 to zero, mean and median\n",
    "no_clean = np.copy(orig_x)\n",
    "clean_zero = DP.clean_data(x)\n",
    "clean_mean = DP.clean_data(x, replace_no_measure_with_mean=True)\n",
    "clean_medi = DP.clean_data(x, replace_no_measure_with_median=True)\n",
    "\n",
    "# Make array to test for later\n",
    "cleanDataArray = [no_clean, clean_zero, clean_mean, clean_medi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Normalizing data:\n",
    "normalizedDataArray=[]\n",
    "for i, data in enumerate(cleanDataArray):\n",
    "    normalizedDataArray.append(DP.normalize(data))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_=2.33572146909e-05 #taken from exploration of basic methods\n",
    "k_folds=5\n",
    "avg_losses=[]\n",
    "avg_preds_all=[]\n",
    "for data in normalizedDataArray:\n",
    "    avg_loss, losses, avg_preds, pred_acc_percents = CV.cross_validation(ME.ridge_regression, orig_y, data, k_folds, lambda_)\n",
    "    avg_losses.append(avg_loss)\n",
    "    avg_preds_all.append(avg_preds)\n",
    "print(\"this is lambda\", lambda_)\n",
    "print(\"this is average losses: \",avg_losses)\n",
    "print(\"this is average prediction error:\",avg_preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Based on this, we choose to continue with the data where all missing values are replaced by 0. \n",
    "\n",
    "chosenData=normalizedDataArray[2]\n",
    "print(chosenData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Now we want to performe PCA on the chosen data\n",
    "numberOfDimensions=(30,29,28,27,26,25,24,23,22,21,20)\n",
    "pcas=[]\n",
    "for i, degree in enumerate(numberOfDimensions):\n",
    "    pca_i=DP.pca(chosenData,degree)[0]\n",
    "    pcas.append(pca_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_=2.33572146909e-05 #taken from exploration of basic methods\n",
    "k_folds=5\n",
    "avg_losses=[]\n",
    "avg_preds_all=[]\n",
    "for data in pcas:\n",
    "    avg_loss, losses, avg_preds, pred_acc_percents = CV.cross_validation(ME.ridge_regression, orig_y, data, k_folds, lambda_)\n",
    "    avg_losses.append(avg_loss)\n",
    "    avg_preds_all.append(avg_preds)\n",
    "print(\"this is lambda\", lambda_)\n",
    "print(\"this is average losses: \",avg_losses)\n",
    "print(\"this is average prediction error:\",avg_preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_loss=np.min(avg_losses)\n",
    "print(minimum_loss)\n",
    "\n",
    "chosenData=pcas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now we want to pick a polynomial degree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "degrees=(3,4,5,6,7,8,9,10,11,13,15,17,19,20)\n",
    "lambdas=np.logspace(-9,1,15)\n",
    "min_loss=1000;\n",
    "min_degree=0;\n",
    "min_lambda=0\n",
    "max_acc=0\n",
    "avg_losses=np.zeros((len(degrees),len(lambdas)))\n",
    "avg_acc=np.zeros((len(degrees),len(lambdas)))\n",
    "for d,degree in enumerate(degrees):\n",
    "    phi=DP.build_poly(chosenData,degree)\n",
    "    for l,lambda_ in enumerate(lambdas):\n",
    "        avg_loss, losses, avg_preds, pred_acc_percents = CV.cross_validation(ME.ridge_regression, orig_y, phi, k_folds, lambda_)\n",
    "        avg_losses[d,l]=avg_loss\n",
    "        avg_acc[d,l]=avg_preds\n",
    "        if avg_loss < min_loss:\n",
    "            min_loss=avg_loss\n",
    "            min_degree=degree\n",
    "            min_lambda=lambda_\n",
    "            max_acc=avg_preds\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min_loss)\n",
    "print(min_degree)\n",
    "print(min_lambda)\n",
    "print(max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#based on this, I want to choose a polynomial of degree \n",
    "#0.781696843395 \n",
    "#7\n",
    "#3.72759372031e-06\n",
    "#0.20651999999999998\n",
    "\n",
    "chosenData=DP.build_poly(chosenData,min_degree)\n",
    "lambda_=min_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_test_x=DP.clean_data(pred_x)\n",
    "clean_train_x=clean_data(orig_x)\n",
    "\n",
    "norm_test_x=DP.normalize(clean_test_x)\n",
    "norm_train_x=DP.normalize(clean_train_x)\n",
    "\n",
    "pca_test=DP.pca(norm_test_x,30)[0]\n",
    "pca_train=DP.pca(norm_train_x,30)[0]\n",
    "\n",
    "phi_test=DP.build_poly(pca_test,7)\n",
    "phi_train=DP.build_poly(pca_train,7)\n",
    "\n",
    "lambda_=3.72759372031e-06\n",
    "degree=7\n",
    "\n",
    "loss,w=ME.ridge_regression(orig_y,phi_train,lambda_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted=P1H.predict_labels(w,phi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_predicted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name=\"testing_hedda.csv\"\n",
    "\n",
    "create_csv_submission(pred_ids, y_predicted, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
