{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# standard libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# own functions\n",
    "from proj1_helpers import * \n",
    "import basic_functions as bf\n",
    "#import plot_functions as pf \n",
    "\n",
    "#constants\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y, orig_x, ids = load_csv_data(train_path, sub_sample=True) #remember to switch of subsample when running it \"for real\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature covariance analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 0.94739732909391594)\n",
      "(4, 6, 0.99998112072399181)\n",
      "(4, 12, 0.99999838789702122)\n",
      "(4, 26, 0.99928496619278129)\n",
      "(4, 27, 0.9999950635258662)\n",
      "(4, 28, 0.99999539954791528)\n",
      "(5, 4, 0.94739732909391605)\n",
      "(5, 6, 0.94581161222813126)\n",
      "(5, 12, 0.94694447317186681)\n",
      "(5, 26, 0.94937668303415901)\n",
      "(5, 27, 0.94688850056787355)\n",
      "(5, 28, 0.94684263382804212)\n",
      "(6, 4, 0.9999811207239917)\n",
      "(6, 5, 0.94581161222813115)\n",
      "(6, 12, 0.99998942464545881)\n",
      "(6, 26, 0.99928254569451991)\n",
      "(6, 27, 0.99998761461605867)\n",
      "(6, 28, 0.99998895691773237)\n",
      "(9, 21, 0.90555154110426728)\n",
      "(9, 29, 0.9710698349712461)\n",
      "(12, 4, 0.99999838789702133)\n",
      "(12, 5, 0.94694447317186681)\n",
      "(12, 6, 0.99998942464545881)\n",
      "(12, 26, 0.99929282028978106)\n",
      "(12, 27, 0.99999700630493649)\n",
      "(12, 28, 0.99999753236344036)\n",
      "(21, 9, 0.90555154110426728)\n",
      "(23, 24, 0.9959522896516706)\n",
      "(23, 25, 0.99595063262941408)\n",
      "(24, 23, 0.99595228965167049)\n",
      "(24, 25, 0.99999152136607705)\n",
      "(25, 23, 0.99595063262941408)\n",
      "(25, 24, 0.99999152136607705)\n",
      "(26, 4, 0.99928496619278129)\n",
      "(26, 5, 0.94937668303415901)\n",
      "(26, 6, 0.99928254569451991)\n",
      "(26, 12, 0.99929282028978106)\n",
      "(26, 27, 0.99928850049174789)\n",
      "(26, 28, 0.9992897858330867)\n",
      "(27, 4, 0.99999506352586631)\n",
      "(27, 5, 0.94688850056787355)\n",
      "(27, 6, 0.99998761461605878)\n",
      "(27, 12, 0.9999970063049366)\n",
      "(27, 26, 0.99928850049174789)\n",
      "(27, 28, 0.99999456646774476)\n",
      "(28, 4, 0.99999539954791528)\n",
      "(28, 5, 0.94684263382804212)\n",
      "(28, 6, 0.99998895691773226)\n",
      "(28, 12, 0.99999753236344036)\n",
      "(28, 26, 0.9992897858330867)\n",
      "(28, 27, 0.99999456646774476)\n",
      "(29, 9, 0.97106983497124622)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def feature_covariance_analysis(x, correleation_threshold):\n",
    "        \n",
    "    corrcoef = np.corrcoef(x, rowvar=False)\n",
    "\n",
    "    threshold = correleation_threshold\n",
    "    covariance_information = []\n",
    "\n",
    "    for j in range(corrcoef.shape[0]):\n",
    "        for k in range(corrcoef.shape[1]): \n",
    "            value = corrcoef[j][k] \n",
    "            if(value > threshold and j != k):\n",
    "                covariance_information.append((j,k,value))\n",
    "                \n",
    "    return covariance_information\n",
    "            \n",
    "covariance_info = feature_covariance_analysis(orig_x, 0.90)\n",
    "\n",
    "for element in covariance_info:\n",
    "        print(element)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggestion: \n",
    "\n",
    "Counts of how many clear covariances with other columns: \n",
    "\n",
    "- 4  : 5 ( K ) \n",
    "- 6  : 5 ( D )\n",
    "\n",
    "- 9  : 1 ( K ) \n",
    "\n",
    "- 12 : 5 ( D) \n",
    "\n",
    "- 23 : 2 ( K ) \n",
    "- 24 : 2 ( D )  \n",
    "- 25 : 2 ( D ) \n",
    "\n",
    "- 26 : 5 ( D )\n",
    "- 27 : 5 ( D ) \n",
    "- 28 : 5 ( D ) \n",
    "\n",
    "- 29 : 1 ( D )\n",
    "\n",
    "Remove the following: \n",
    "\n",
    "- 9 has only one strong correleation, with 29. Remove 29 \n",
    "- Covariance with 4, 6, 12 is present in the following: 28, 27, 26. Suggest to remove 26,27,28. \n",
    "- 23, 24 and 25 are highly corrolated with eachother, delete 24,25 \n",
    "- 4, 5, 6 and 12 are highly corrolated with eachother, delete 5, 6, 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing features and doing the same over again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 21)\n",
      "(3, 7, 0.83412591904602407)\n",
      "(3, 18, 0.78280479853168883)\n",
      "(4, 19, 0.86788984915208112)\n",
      "(7, 3, 0.83412591904602418)\n",
      "(7, 18, 0.90555154110426772)\n",
      "(18, 3, 0.78280479853168872)\n",
      "(18, 7, 0.90555154110426761)\n",
      "(19, 4, 0.86788984915208112)\n",
      "(19, 20, 0.83318372461198409)\n",
      "(20, 19, 0.83318372461198409)\n"
     ]
    }
   ],
   "source": [
    "x = np.delete(orig_x, [5, 6, 12, 24,25,26,27,28,29], axis=1)  # remove columns 1 and 2\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "covariance_info = feature_covariance_analysis(x, 0.75)\n",
    "\n",
    "for element in covariance_info:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We se that we have reduced the corrolation by a LOT. Good shit\n",
    "\n",
    "We removed 5, 6, 12, 24, 25, 26, 27, 28, 29 due to HIGH corrolation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method for removing the highly corrolated columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_highly_corrolated_features(data):\n",
    "    \n",
    "    return np.delete(data, [5, 6, 12, 24,25,26,27,28,29], axis=1) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
