{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the usual stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# own functions\n",
    "from proj1_helpers import *\n",
    "from methods import *\n",
    "from grad_loss import *\n",
    "from dataprocessing import*\n",
    "import cross_validation as cv\n",
    "#import plot_functions as pf \n",
    "\n",
    "#constants\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing data: \n",
    "y, x, ids = load_csv_data(train_path, sub_sample=False) #remember to switch of subsample when running it \"for real\"\n",
    "pred_y, pred_x, pred_ids = load_csv_data(test_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median_x=clean_data(x, replace_no_measure_with_mean = False, replace_no_measure_with_median = True)\n",
    "mean_x=clean_data(x, replace_no_measure_with_mean = True, replace_no_measure_with_median = False)\n",
    "mean_norm=normalize(mean_x)\n",
    "#median_norm=normalize(median_x)\n",
    "nx_mean=normalize(inverse_log_non_neg(mean_x))\n",
    "#nx_median=normalize(inverse_log_non_neg(median_x))\n",
    "\n",
    "pred_mean_x=clean_data(pred_x, replace_no_measure_with_mean = True, replace_no_measure_with_median = False)\n",
    "pred_mean_norm=normalize(pred_mean_x)\n",
    "pred_nx_mean=normalize(inverse_log_non_neg(pred_mean_x))\n",
    "#pca1 = pca(mean_norm, 30)[0]\n",
    "#pca2=  pca(median_norm, 20)[0]\n",
    "#pca3 = pca(nx_median, 30)[0]\n",
    "#pca4=  pca(nx_median, 20)[0]\n",
    "\n",
    "\n",
    "#ALL_THE_DATA = np.vstack((x, pred_x))\n",
    "#pca5 = pca(ALL_THE_DATA, 30)[0]\n",
    "#split = x.shape[0]\n",
    "#pca_all=pca5[:split]\n",
    "\n",
    "#data=(mean_norm,median_norm,nx_mean,nx_median,pca1,pca2,pca3,pca4,pca_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_=0.00000000001\n",
    "k_folds = 5\n",
    "\n",
    "average_losses=[]\n",
    "average_accs=[]\n",
    "\n",
    "\n",
    "for tx in data:\n",
    "    phi=build_poly(tx,5)\n",
    "    avg_loss, losses, avg_preds, pred_acc_percents = cv.cross_validation(ridge_regression, y, phi, k_folds, lambda_)\n",
    "    average_losses.append(avg_loss)\n",
    "    average_accs.append(avg_preds)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_losses) \n",
    "print(average_accs)## med poly 6: 0.342668, 0.32494, 0.20451999999999998, 0.482472, 0.657328, 0.215856, 0.57538, 0.21451199999999998, 0.225528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##want to use data: nx_mean\n",
    "lambda_=0.00000000001\n",
    "phi=build_poly(nx_mean,5)\n",
    "rmse,w=ridge_regression(y, phi, lambda_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_phi=build_poly(pred_nx_mean,5)\n",
    "pred_y=predict_labels(w, pred_phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'pca_poly3.csv'\n",
    "create_csv_submission(pred_ids, pred_y, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
