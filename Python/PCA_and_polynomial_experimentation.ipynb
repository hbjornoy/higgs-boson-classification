{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA and polynomial experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# own functions\n",
    "from proj1_helpers import *\n",
    "import basic_functions as bf\n",
    "import cross_validation as cv\n",
    "#import plot_functions as pf \n",
    "\n",
    "#constants\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w_ridge, rmse_ridge=      bf.ridge_regression(y_tr, x_tr, lambda_)\n",
    "\n",
    "#loss_reglogreg, w_reglogreg, losses_reglogreg=    bf.reg_logistic_regression(y_tr, tx_tr, lambda_, initial_w, max_iters, gamma)\n",
    "\n",
    "\n",
    "#*args = hyperparameters \n",
    "\n",
    "def cross_validation(function_to_run, y, x, num_of_k_fold, *args):\n",
    "    \n",
    "    losses = []\n",
    "    pred_acc_percents = []\n",
    "    \n",
    "    k_indices = cv.build_k_indices(y, num_of_k_fold, 1)\n",
    "    \n",
    "    for k in range(num_of_k_fold):\n",
    "        \n",
    "        x_test, y_test, x_tr, y_tr = cv.split_k(x,y,k_indices, k)\n",
    "        \n",
    "        if(function_to_run.__name__ == \"reg_logistic_regression\"):\n",
    "            \n",
    "            lambda_ = args[0]\n",
    "            initial_w = args[1]\n",
    "            max_iters = args[2]\n",
    "            gamma = args[3]\n",
    "            \n",
    "            loss, weights, losses =  function_to_run(y_tr, x_tr, lambda_, initial_w, max_iters, gamma) \n",
    "            \n",
    "        elif(function_to_run.__name__ == \"ridge_regression\"):\n",
    "            \n",
    "            lambda_ = args[0]\n",
    "            \n",
    "            weights, loss = bf.ridge_regression(y, x, lambda_)\n",
    "        \n",
    "        elif(function_to_run.__name__ == \"least_squares\"):\n",
    "            \n",
    "            ty = np.transpose(y)\n",
    "            \n",
    "            loss, weights = bf.least_squares(ty, x)\n",
    "            \n",
    "            \n",
    "        losses.append(loss)\n",
    "\n",
    "        pred_y = bf.log_pred(x, weights)    \n",
    "        pred_acc_percent, soppel = bf.log_pred_acc(y, pred_y)\n",
    "        pred_acc_percents.append(pred_acc_percent)\n",
    "     \n",
    "    \n",
    "    loss_sum = 0\n",
    "    for loss in losses:\n",
    "        loss_sum += loss\n",
    "    avg_loss = loss_sum / len(losses)\n",
    "    \n",
    "    acc_sum = 0\n",
    "    for acc in pred_acc_percents:\n",
    "        acc_sum += acc\n",
    "    avg_acc = acc_sum / len(pred_acc_percents)\n",
    "    \n",
    "    return avg_loss, losses, avg_acc, pred_acc_percents \n",
    "\n",
    "\n",
    "lambda_=0.000000000001\n",
    "initial_w = np.zeros((x.shape[1], 1))\n",
    "max_iters = 5\n",
    "gamma = 0.01\n",
    "k_folds = 5\n",
    "\n",
    "#avg_loss, losses, avg_preds, pred_acc_percents = cross_validation(bf.ridge_regression, y, phi, k_folds, lambda_)\n",
    "#avg_loss, losses, avg_preds, pred_acc_percents = cross_validation(bf.least_squares, y, x, k_folds)\n",
    "#avg_loss, losses, avg_preds, pred_acc_percents = cross_validation(bf.reg_logistic_regression, y, phi, k_folds, lambda_, initial_w, max_iters, gamma)\n",
    "\n",
    "print(\"avg loss: \", avg_loss)\n",
    "print(\"Losses: \", losses)\n",
    "print(\"Average prediction NON-accuracy: \", avg_preds)\n",
    "print(\"prediction NON-accuracy percents: \", pred_acc_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca(data, pc_count = None):\n",
    "    \"\"\"\n",
    "    Principal component analysis using eigenvalues\n",
    "    note: this mean-centers and auto-scales the data (in-place)\n",
    "    \"\"\"\n",
    "    data -= np.mean(data, 0)\n",
    "    data /= np.std(data, 0)\n",
    "    \n",
    "    \"\"\"\n",
    "    Covariance matrix\n",
    "    note: specifically for mean-centered data\n",
    "    note: numpy's `cov` uses N-1 as normalization\n",
    "    \"\"\"\n",
    "    C = np.dot(data.T, data) / data.shape[0]\n",
    "    E, V = np.linalg.eigh(C)\n",
    "    key = np.argsort(E)[::-1][:pc_count]\n",
    "    E, V = E[key], V[:, key]\n",
    "    U = np.dot(data, V)  # used to be dot(V.T, data.T).T\n",
    "    return U, E, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing data: \n",
    "y, x, ids = load_csv_data(train_path, sub_sample=True) #remember to switch of subsample when running it \"for real\"\n",
    "pred_y, pred_x, pred_ids = load_csv_data(test_path, sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1\n",
    "ratio = 0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.copy(x)\n",
    "degrees=(1,2,3,4,5,6)#,7,8,9,10,11,12,13,14)\n",
    "lambdas=np.logspace(-8,3,11)\n",
    "rmses_tr=np.zeros((len(degrees),len(lambdas)))\n",
    "rmses_te=np.zeros((len(degrees),len(lambdas)))\n",
    "\n",
    "# Using PCA on the data before split so that the train and testset get the same eigenvectors\n",
    "data = pca(data, 30)[0]\n",
    "\n",
    "for d, degree in enumerate(degrees): \n",
    "    \n",
    "    #bulding polynomial\n",
    "    phi=bf.build_poly(data, degree)\n",
    "    print(phi.shape)\n",
    "    \n",
    "    #splitting data\n",
    "    x_tr, x_te, y_tr, y_te = bf.split_data(phi, y, ratio, seed)\n",
    "    \n",
    "    #Normalizing data\n",
    "    #x_tr=bf.normalize(x_tr)\n",
    "    #x_te=bf.normalize(x_te)\n",
    "    \n",
    "    for l, lambda_ in enumerate(lambdas):\n",
    "        #preforming ridge regression\n",
    "        w, rmse_tr=bf.ridge_regression(y_tr, x_tr, lambda_)\n",
    "        rmses_tr[d,l]=rmse_tr\n",
    "        rmse_te=np.sqrt(2*bf.get_mse(y_te, x_te, w))\n",
    "        rmses_te[d,l]=rmse_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees,rmses_tr[:,0],color='b', marker='*', label=\"Train error 1\")\n",
    "plt.plot(degrees,rmses_tr[:,1],color='r', marker='*', label=\"Train error 2\")\n",
    "plt.plot(degrees,rmses_tr[:,2],color='g', marker='*', label=\"Train error 3\")\n",
    "plt.plot(degrees,rmses_tr[:,3],color='m', marker='*', label=\"Train error 4\")\n",
    "plt.plot(degrees,rmses_tr[:,4],color='y', marker='*', label=\"Train error 5\")\n",
    "plt.plot(degrees,rmses_tr[:,5],color='b', marker='*', label=\"Train error 6\")\n",
    "plt.plot(degrees,rmses_tr[:,6],color='r', marker='*', label=\"Train error 7\")\n",
    "plt.plot(degrees,rmses_tr[:,7],color='g', marker='*', label=\"Train error 8\")\n",
    "plt.plot(degrees,rmses_tr[:,8],color='m', marker='*', label=\"Train error 9\")\n",
    "plt.plot(degrees,rmses_tr[:,9],color='m', marker='*', label=\"Train error 10\")\n",
    "leg = plt.legend(loc=1, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees,rmses_te[:,0],color='b', marker='*', label=\"Test error 1\")\n",
    "plt.plot(degrees,rmses_te[:,1],color='r', marker='*', label=\"Test error 2\")\n",
    "plt.plot(degrees,rmses_te[:,2],color='g', marker='*', label=\"Test error 3\")\n",
    "plt.plot(degrees,rmses_te[:,3],color='m', marker='*', label=\"Test error 4\")\n",
    "plt.plot(degrees,rmses_te[:,4],color='y', marker='*', label=\"Test error 5\")\n",
    "plt.plot(degrees,rmses_te[:,5],color='b', marker='*', label=\"Test error 6\")\n",
    "plt.plot(degrees,rmses_te[:,6],color='r', marker='*', label=\"Test error 7\")\n",
    "plt.plot(degrees,rmses_te[:,7],color='g', marker='*', label=\"Test error 8\")\n",
    "plt.plot(degrees,rmses_te[:,8],color='m', marker='*', label=\"Test error 9\")\n",
    "plt.plot(degrees,rmses_te[:,9],color='m', marker='*', label=\"Test error 10\")\n",
    "leg = plt.legend(loc=1, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees,rmses_te[:,0],color='b', marker='*', label=\"Test error 1\")\n",
    "plt.plot(degrees,rmses_tr[:,0],color='r', marker='*', label=\"Train error 1\")\n",
    "leg = plt.legend(loc=1, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees,rmses_tr[:,0],color='b', marker='*', label=\"Train error 1\")\n",
    "plt.plot(degrees,rmses_tr[:,1],color='b', marker='*', label=\"Train error 2\")\n",
    "plt.plot(degrees,rmses_tr[:,2],color='b', marker='*', label=\"Train error 3\")\n",
    "plt.plot(degrees,rmses_tr[:,3],color='b', marker='*', label=\"Train error 4\")\n",
    "plt.plot(degrees,rmses_tr[:,4],color='b', marker='*', label=\"Train error 5\")\n",
    "plt.plot(degrees,rmses_te[:,0],color='r', marker='*', label=\"Test error 1\")\n",
    "plt.plot(degrees,rmses_te[:,1],color='y', marker='*', label=\"Test error 2\")\n",
    "plt.plot(degrees,rmses_te[:,2],color='g', marker='*', label=\"Test error 3\")\n",
    "plt.plot(degrees,rmses_te[:,3],color='m', marker='*', label=\"Test error 4\")\n",
    "plt.plot(degrees,rmses_te[:,4],color='black', marker='*', label=\"Test error 5\")\n",
    "leg = plt.legend(loc=1, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(degrees,rmses_tr[:,5],color='grey', marker='*', label=\"Train error 6\")\n",
    "plt.plot(degrees,rmses_tr[:,6],color='b', marker='*', label=\"Train error 7\")\n",
    "plt.plot(degrees,rmses_tr[:,7],color='b', marker='*', label=\"Train error 8\")\n",
    "plt.plot(degrees,rmses_tr[:,8],color='b', marker='*', label=\"Train error 9\")\n",
    "plt.plot(degrees,rmses_tr[:,9],color='b', marker='*', label=\"Train error 10\")\n",
    "plt.plot(degrees,rmses_te[:,5],color='r', marker='*', label=\"Test error 6\")\n",
    "plt.plot(degrees,rmses_te[:,6],color='g', marker='*', label=\"Test error 7\")\n",
    "plt.plot(degrees,rmses_te[:,7],color='y', marker='*', label=\"Test error 8\")\n",
    "plt.plot(degrees,rmses_te[:,8],color='m', marker='*', label=\"Test error 9\")\n",
    "plt.plot(degrees,rmses_te[:,9],color='black', marker='*', label=\"Test error 10\")\n",
    "leg = plt.legend(loc=1, shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi=bf.build_poly(x, 5)\n",
    "#splitting data\n",
    "#x_tr, x_te, y_tr, y_te = bf.split_data(phi, y, ratio, seed)\n",
    "x_tr=x\n",
    "y_tr=y\n",
    "#Normalizing data\n",
    "x_tr=bf.normalize(x_tr)\n",
    "#x_te=bf.normalize(x_te)\n",
    "w, rmse_tr=bf.ridge_regression(y_tr, x_tr, lambdas[4])\n",
    "rmse_tr_cho=rmse_tr\n",
    "#rmse_te_cho=np.sqrt(2*bf.get_mse(y_te, x_te, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_tr_cho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_labels(w, x_tr)\n",
    "print(y_pred[1:25])\n",
    "p,c=bf.log_pred_acc(y_tr,y_pred)\n",
    "print(p,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do over for delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Doing PCA on all of the train.csv and test.csv, because it doesn't need labels. Not following Ma chine learning\n",
    "honor code\n",
    "\"\"\"\n",
    "#Importing data: \n",
    "y, x, ids = load_csv_data(train_path, sub_sample=False) #remember to switch of subsample when running it \"for real\"\n",
    "pred_y, pred_x, pred_ids = load_csv_data(test_path, sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining train.csv and test.csv\n",
    "ALL_THE_DATA = np.vstack((x, pred_x))\n",
    "print(x.shape, pred_x.shape)\n",
    "print(ALL_THE_DATA.shape)\n",
    "\n",
    "# Using PCA on the data before split so that the train and testset get the same eigenvectors\n",
    "data = pca(ALL_THE_DATA, 30)[0]\n",
    "\n",
    "#bulding polynomial\n",
    "degree = 6\n",
    "phi=bf.build_poly(data, degree)\n",
    "\n",
    "# Regression to find weights in just the train.csv data\n",
    "# assuming that the datapoints have not been abstracted but only \n",
    "split = x.shape[0]\n",
    "print(split)\n",
    "weights, loss = bf.ridge_regression(y, phi[:split], lambda_)\n",
    "print(weights.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "lambda_=0.00000000000001\n",
    "#initial_w = np.zeros((x.shape[1], 1))\n",
    "#max_iters = 5\n",
    "#gamma = 0.01\n",
    "k_folds = 5\n",
    "\n",
    "avg_loss, losses, avg_preds, pred_acc_percents = cross_validation(bf.ridge_regression, y, phi[:split], k_folds, lambda_)\n",
    "#avg_loss, losses, avg_preds, pred_acc_percents = cross_validation(bf.least_squares, y, x, k_folds)\n",
    "#avg_loss, losses, avg_preds, pred_acc_percents = cross_validation(bf.reg_logistic_regression, y, phi, k_folds, lambda_, initial_w, max_iters, gamma)\n",
    "\n",
    "print(\"avg loss: \", avg_loss)\n",
    "print(\"Losses: \", losses)\n",
    "print(\"Average prediction NON-accuracy: \", avg_preds)\n",
    "print(\"prediction NON-accuracy percents: \", pred_acc_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "print(phi[:split].shape)\n",
    "y_pred = predict_labels(weights, phi[split:])\n",
    "print(y_pred.shape)\n",
    "print(pred_ids.shape)\n",
    "print(y_pred.mean())\n",
    "print(y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'pca_poly2.csv'\n",
    "create_csv_submission(pred_ids, y_pred, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
